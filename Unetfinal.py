# -*- coding: utf-8 -*-
"""Different Data Format.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13zAONVZYD6BuCyKcqembWEnfAe5V6IHK
"""

# Loading libraries

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
from statistics import mean
from torch.autograd import Variable
import time
from PIL import Image
import random
from skimage import io, transform
from collections import OrderedDict
import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms, utils
from torch import nn

from torch.autograd import Variable
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam, SGD
from matplotlib import pyplot as plt
from torch.optim.lr_scheduler import ReduceLROnPlateau
from collections import OrderedDict
import argparse

###
import matplotlib
matplotlib.use("Agg")
###
## ARGPARSE ADAPTED FROM: Luke's MonArch/Spyder Videos on Moodle
parser = argparse.ArgumentParser(description="Train Unet")
# Required args
parser.add_argument("--save_name", help="Experiment prefix", required=True)
parser.add_argument("--save_dir", help="Save directory location", required=True)
# String args
parser.add_argument("--data_dir", help="Root dataset directory", default="kaggle_3m")
# int args
parser.add_argument("--batch_size", help="Batch size", type=int, default=5)
parser.add_argument("--epochs", help="num training epochs", type=int, default=10)
# float args
parser.add_argument("--lr", help="learning rate", type=float, default=0.15)
# bool args
parser.add_argument("--load_checkpoint", action='store_true', help="load checkpoint or start from scratch")

args=parser.parse_args()
start_epoch= 0

#Set device to GPU_indx if GPU is avaliable
GPU_indx = 0
device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')
print(device)

csv_path =  '/kaggle_3m/data.csv'
data_folder = '/kaggle_3m/'
eg_path = '/kaggle_3m/TCGA_HT_8113_19930809'
eg_img = '/kaggle_3m/TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_10.tif'
eg_mask = '/kaggle_3m/TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_10_mask.tif'


mean, std = 0.5, 0.5
shape = 256

transform = transforms.Compose([
    transforms.ToTensor()

])

transform_test = transforms.Compose([
    transforms.ToTensor()
    ])
###################################################################################################
## BRAIN DATA CLASS ADAPTED FROM: https://www.kaggle.com/arunmohan003/pytorch-brain-mri-segmentation-unet
class Brain_data(Dataset):
    def __init__(self,path, transform_img, transform_mask):
        self.path = path
        self.patients = [file for file in os.listdir(path) if file not in ['data.csv','README.md']]
        self.masks,self.images = [],[]

        for patient in self.patients:
            for file in os.listdir(os.path.join(self.path,patient)):
                if 'mask' in file.split('.')[0].split('_'):
                    self.masks.append(os.path.join(self.path,patient,file))
                else: 
                    self.images.append(os.path.join(self.path,patient,file)) 
          
        self.images = sorted(self.images)
        self.masks = sorted(self.masks)
        self.transform_img = transform_img
        self.transform_mask = transform_mask
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self,idx):
        image = self.images[idx]
        mask = self.masks[idx]
        
        image = io.imread(image)
        image = self.transform_img(image)

        mask = io.imread(mask)
        mask = self.transform_mask(mask)

        return (image,mask)

data = Brain_data(args.data_dir, transform, transform)
data_test = Brain_data(args.data_dir, transform_test, transform_test)
print('Length of dataset is {}'. format(data.__len__()))
print('sample data: ')
data.__getitem__(0)
data_test.__getitem__(0)
#######################################################################################################
# splitting to trainset and validation set

# trainset, valset = random_split(data, [3600, 329])
trainset, valset, _ = random_split(data, [3200, 400, 329])
testset, _ = random_split(data_test, [700, 3229])

train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=3,shuffle=True)

val_loader = torch.utils.data.DataLoader(dataset=valset, batch_size=3)

test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=10)


#####################################################################################################
## UNET MODEL FROM: https://github.com/mateuszbuda/brain-segmentation-pytorch

def double_conv(in_channels, out_channels):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3, padding=1,bias=False),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channels, out_channels, 3, padding=1,bias=False),
        nn.ReLU(inplace=True))
    
class UNet(nn.Module):

    def __init__(self, in_channels=3, out_channels=1, init_features=32):
        super(UNet, self).__init__()

        features = init_features
        self.encoder1 = UNet._block(in_channels, features, name="enc1")
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder2 = UNet._block(features, features * 2, name="enc2")
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder3 = UNet._block(features * 2, features * 4, name="enc3")
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder4 = UNet._block(features * 4, features * 8, name="enc4")
        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.bottleneck = UNet._block(features * 8, features * 16, name="bottleneck")

        self.upconv4 = nn.ConvTranspose2d(
            features * 16, features * 8, kernel_size=2, stride=2
        )
        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name="dec4")
        self.upconv3 = nn.ConvTranspose2d(
            features * 8, features * 4, kernel_size=2, stride=2
        )
        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name="dec3")
        self.upconv2 = nn.ConvTranspose2d(
            features * 4, features * 2, kernel_size=2, stride=2
        )
        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name="dec2")
        self.upconv1 = nn.ConvTranspose2d(
            features * 2, features, kernel_size=2, stride=2
        )
        self.decoder1 = UNet._block(features * 2, features, name="dec1")

        self.conv = nn.Conv2d(
            in_channels=features, out_channels=out_channels, kernel_size=1
        )

    def forward(self, x):
        #print(x.shape)
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(self.pool1(enc1))
        enc3 = self.encoder3(self.pool2(enc2))
        enc4 = self.encoder4(self.pool3(enc3))

        bottleneck = self.bottleneck(self.pool4(enc4))

        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.decoder4(dec4)
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.decoder3(dec3)
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.decoder2(dec2)
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.decoder1(dec1)
        #print(dec1.shape)
        return torch.sigmoid(self.conv(dec1))

    @staticmethod
    def _block(in_channels, features, name):
        return nn.Sequential(
            OrderedDict(
                [
                    (
                        name + "conv1",
                        nn.Conv2d(
                            in_channels=in_channels,
                            out_channels=features,
                            kernel_size=3,
                            padding=1,
                            bias=False,
                        ),
                    ),
                    (name + "norm1", nn.BatchNorm2d(num_features=features)),
                    (name + "relu1", nn.ReLU(inplace=True)),
                    (
                        name + "conv2",
                        nn.Conv2d(
                            in_channels=features,
                            out_channels=features,
                            kernel_size=3,
                            padding=1,
                            bias=False,
                        ),
                    ),
                    (name + "norm2", nn.BatchNorm2d(num_features=features)),
                    (name + "relu2", nn.ReLU(inplace=True)),
                ]
            )
        )
#####################################################################################################

model = UNet().to(device)


## FUNCTIONS FROM: https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch
def DiceLoss(inputs, targets, smooth=1):
    inputs = inputs.view(-1)
    targets = targets.view(-1)
    intersection = (inputs*targets).sum()
    dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)
    return 1 - dice

def dice_loss(pred,target,e=1e-6):
    inter=2*(pred*target).sum()+e
    union=(pred).sum()+(target).sum()+e
    return 1-(inter/union).sum()

def bce_dice_loss(inputs, target):
    dicescore = dice_loss(inputs, target)
    bcescore = nn.BCELoss()
    bceloss = bcescore(inputs, target)
    
    return dicescore + bceloss
####################################################################################################
learning_rate = 0.3 #1e-3
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor=0.75, patience=4)
epochs = 40

train_loss = []
val_loss = []

#####################################################################################################
## SAVING/CHECKPOINT FROM: Luke's MonArch/Spyder videos on Moodle.

#Create save path from save_dir and model_name, we will save and load checkpoint here
Save_Path = os.path.join(args.save_dir, args.save_name + ".pt")

#Create the save directory if it does not exist
if not os.path.isdir(args.save_dir):
    os.makedirs(args.save_dir)
    
#Load checkpoint
if args.load_checkpoint:
    #Check if checkpoint exists
    if os.path.isfile(Save_Path):
        #load checkpoint
        check_point = torch.load(Save_Path)
        
        model.load_state_dict(check_point['model_state_dict'])
        optimizer.load_state_dict(check_point['optimizer_state_dict'])
        start_epoch = check_point['epoch']
        train_loss = check_point['train_loss']
        val_loss = check_point['validation_loss']
        
        print("Checkpoint loaded, starting from epoch: start_epoch")
    else:
        print("Checkpoint does not exist, starting from scratch")
else:
    if os.path.isfile(Save_Path):
        raise ValueError("Warning Checkpoint exists")
    else:
        print("Starting from scratch")        
           
#####################################################################################################
## TRAINING LOOPS ADAPTED FROM: https://www.kaggle.com/arunmohan003/pytorch-brain-mri-segmentation-unet

for epoch in range(epochs):
    print('Epoch {}/{}'.format(epoch + 1, epochs))
    start_time = time.time()
     
     
    running_train_loss = []
    
    for image,mask in train_loader: 
            image = image.to(device,dtype=torch.float)#
            mask = mask.to(device,dtype=torch.float)#

            pred_mask = model(image) # forward propogation
            #loss = DiceLoss(pred_mask,mask)
            loss = bce_dice_loss(pred_mask, mask)
            optimizer.zero_grad() # setting gradient to zero
            loss.backward()
            optimizer.step()
            running_train_loss.append(loss.item())
                              

    else:           
        running_val_loss = []
        
        with torch.no_grad():
            for image,mask in val_loader:
                    image = image.to(device,dtype=torch.float)#
                    mask = mask.to(device,dtype=torch.float)#      

                    pred_mask = model(image)
                    #loss = DiceLoss(pred_mask,mask)
                    loss = bce_dice_loss(pred_mask, mask)
                    running_val_loss.append(loss.item())
    

    epoch_train_loss = np.mean(running_train_loss) 
    print('Train loss: {}'.format(epoch_train_loss))                       
    train_loss.append(epoch_train_loss)
    
    epoch_val_loss = np.mean(running_val_loss)
    print('Validation loss: {}'.format(epoch_val_loss))                                
    val_loss.append(epoch_val_loss)
    
    scheduler.step(epoch_val_loss)
                      
    time_elapsed = time.time() - start_time
    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

    torch.save({
        'epoch': epoch+1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_loss': train_loss,
        'validation_loss': val_loss
        }, Save_Path)

plt.figure(5)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot(train_loss,label='Training Loss')
plt.plot(val_loss,label='Validation Loss')
plt.legend()
plt.title('Dice Loss Plot for U-Net')
plt.savefig("Train_Val_Losses_unet.png")


#################################################################################################
##VIEWING RESULTS ADAPTED FROM: https://www.kaggle.com/kasevgen/pytorch-segmentation


def plot_result(model, loader, ax, shape):
    images, target = next(iter(loader))
    ind = np.random.choice(range(loader.batch_size))

    pred = model(images[ind].view(1, 3, shape, shape).to(device)).cpu().detach()[0].permute(1, 2, 0).reshape(shape, shape)
    
    image = images[ind].permute(1, 2, 0)
    target = target[ind].permute(1, 2, 0).reshape(shape, shape)
    target = Image.fromarray(np.asarray(target * 255, dtype=np.uint8)).convert('RGB')
    pred = Image.fromarray(np.asarray(pred * 255, dtype=np.uint8)).convert('RGB')
    
    target = np.asarray(target)
    pred = np.asarray(pred)
    
    ax.imshow(np.hstack([image, target, pred]))
    ax.set_title('U-Net Results: (Image, Ground Truth, Prediction)', fontsize=14)
    plt.savefig("output_unet_predictions.png")

fig, axes = plt.subplots(nrows=10, ncols=4, figsize=(60, 40))
for ax in axes.flatten():
    plot_result(model=model, loader=test_loader, shape=shape, ax=ax)
################################################################################################
print("everything has run @@@@@@@@@@@@@@@@@@")





